{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarcasm_basic_1(stem_lemm_!pos).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3HhM4VVzp6Q",
        "outputId": "d90eb508-3730-40a1-eb0b-1a0ccf317b9d"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW4DI5Dqs64f"
      },
      "source": [
        "import pandas as pd, numpy as np, re, time\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwU740Vqux-p"
      },
      "source": [
        "# Loading data from json file\r\n",
        "data = pd.read_json('Sarcasm_Headlines_Dataset_v2.json', lines = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emyRdte1u0sf",
        "outputId": "44b5aa09-da60-460b-f51f-c146fc308c73"
      },
      "source": [
        "print(data.isnull().any(axis = 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_sarcastic    False\n",
            "headline        False\n",
            "article_link    False\n",
            "dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "jg4z_UmGvR3C",
        "outputId": "ac9535e5-2a10-4967-a884-0596fd95b1bd"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                       article_link\n",
              "0             1  ...  https://www.theonion.com/thirtysomething-scien...\n",
              "1             0  ...  https://www.huffingtonpost.com/entry/donna-edw...\n",
              "2             0  ...  https://www.huffingtonpost.com/entry/eat-your-...\n",
              "3             1  ...  https://local.theonion.com/inclement-weather-p...\n",
              "4             1  ...  https://www.theonion.com/mother-comes-pretty-c...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uctqlUQRu3bP"
      },
      "source": [
        "# Relacing special symbols and digits in headline column\r\n",
        "# re stands for Regular Expression\r\n",
        "data['headline'] = data['headline'].apply(lambda s : re.sub('[^a-zA-Z]', ' ', s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "bC0ggmtGwish",
        "outputId": "882864a9-0356-40d9-c204-db05ec44b82a"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep  totally nails why congress is falling...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies    deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word  strea...</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                       article_link\n",
              "0             1  ...  https://www.theonion.com/thirtysomething-scien...\n",
              "1             0  ...  https://www.huffingtonpost.com/entry/donna-edw...\n",
              "2             0  ...  https://www.huffingtonpost.com/entry/eat-your-...\n",
              "3             1  ...  https://local.theonion.com/inclement-weather-p...\n",
              "4             1  ...  https://www.theonion.com/mother-comes-pretty-c...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRAjZ64vu31w"
      },
      "source": [
        "# getting features and labels\r\n",
        "features = data['headline']\r\n",
        "labels = data['is_sarcastic']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRmDulTNxT84",
        "outputId": "67186411-5803-487c-dfe8-a1c59f0018a5"
      },
      "source": [
        "print(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        thirtysomething scientists unveil doomsday clo...\n",
            "1        dem rep  totally nails why congress is falling...\n",
            "2        eat your veggies    deliciously different recipes\n",
            "3        inclement weather prevents liar from getting t...\n",
            "4        mother comes pretty close to using word  strea...\n",
            "                               ...                        \n",
            "28614         jews to celebrate rosh hashasha or something\n",
            "28615    internal affairs investigator disappointed con...\n",
            "28616    the most beautiful acceptance speech this week...\n",
            "28617    mars probe destroyed by orbiting spielberg gat...\n",
            "28618                   dad clarifies this not a food stop\n",
            "Name: headline, Length: 28619, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVaOZK6Wu5qX"
      },
      "source": [
        "# Stemming our data\r\n",
        "ps = PorterStemmer()\r\n",
        "features = features.apply(lambda x: x.split())\r\n",
        "featuresps = features.apply(lambda x : ' '.join([ps.stem(word) for word in x]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCNR1ohKzLzP"
      },
      "source": [
        "lm = WordNetLemmatizer()\r\n",
        "featureslm = features.apply(lambda x : ' '.join([lm.lemmatize(word, tag) for word in x]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdKNQo9SxVnA",
        "outputId": "580ac6ad-4fa7-40fa-aca0-ff5852c43a53"
      },
      "source": [
        "print(featuresps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        thirtysometh scientist unveil doomsday clock o...\n",
            "1        dem rep total nail whi congress is fall short ...\n",
            "2                       eat your veggi delici differ recip\n",
            "3          inclement weather prevent liar from get to work\n",
            "4        mother come pretti close to use word stream co...\n",
            "                               ...                        \n",
            "28614                jew to celebr rosh hashasha or someth\n",
            "28615    intern affair investig disappoint conspiraci d...\n",
            "28616    the most beauti accept speech thi week came fr...\n",
            "28617    mar probe destroy by orbit spielberg gate spac...\n",
            "28618                      dad clarifi thi not a food stop\n",
            "Name: headline, Length: 28619, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSJGKijPzY06",
        "outputId": "854e2917-f1ad-4bce-d2eb-6fca0af63d57"
      },
      "source": [
        "print(featureslm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        thirtysomething scientist unveil doomsday cloc...\n",
            "1        dem rep totally nail why congress is falling s...\n",
            "2             eat your veggie deliciously different recipe\n",
            "3        inclement weather prevents liar from getting t...\n",
            "4        mother come pretty close to using word streami...\n",
            "                               ...                        \n",
            "28614          jew to celebrate rosh hashasha or something\n",
            "28615    internal affair investigator disappointed cons...\n",
            "28616    the most beautiful acceptance speech this week...\n",
            "28617    mar probe destroyed by orbiting spielberg gate...\n",
            "28618                   dad clarifies this not a food stop\n",
            "Name: headline, Length: 28619, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IshpyTJJu7mw"
      },
      "source": [
        "# vectorizing the data with maximum of 5000 features\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "tv = TfidfVectorizer(max_features = 5000)\r\n",
        "features = list(featureslm)\r\n",
        "features = tv.fit_transform(features).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVpx4GvYu9Zo"
      },
      "source": [
        "# getting training and testing data\r\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = .20, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oesqfpXHu_RX",
        "outputId": "fe3b6983-cf21-4131-9b43-fda258c9564b"
      },
      "source": [
        "# model 1:-\r\n",
        "# Using linear support vector classifier\r\n",
        "lsvc = LinearSVC()\r\n",
        "# training the model\r\n",
        "lsvc.fit(features_train, labels_train)\r\n",
        "# getting the score of train and test data\r\n",
        "print(lsvc.score(features_train, labels_train)) # 90.93\r\n",
        "print(lsvc.score(features_test, labels_test))   # 83.75\r\n",
        "# model 2:-\r\n",
        "# Using Gaussuan Naive Bayes\r\n",
        "gnb = GaussianNB()\r\n",
        "gnb.fit(features_train, labels_train)\r\n",
        "print(gnb.score(features_train, labels_train))  # 78.86\r\n",
        "print(gnb.score(features_test, labels_test))    # 73.80\r\n",
        "# model 3:-\r\n",
        "# Logistic Regression\r\n",
        "lr = LogisticRegression()\r\n",
        "lr.fit(features_train, labels_train)\r\n",
        "print(lr.score(features_train, labels_train))   # 88.16\r\n",
        "print(lr.score(features_test, labels_test))     # 83.08\r\n",
        "# model 4:-\r\n",
        "# Random Forest Classifier\r\n",
        "rfc = RandomForestClassifier(n_estimators = 10, random_state = 0)\r\n",
        "rfc.fit(features_train, labels_train)\r\n",
        "print(rfc.score(features_train, labels_train))  # 98.82\r\n",
        "print(rfc.score(features_test, labels_test))    # 79.71\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9152653417776807\n",
            "0.8270440251572327\n",
            "0.8108320594016161\n",
            "0.7372466806429071\n",
            "0.8822013540074252\n",
            "0.8305380852550663\n",
            "0.9884690980563442\n",
            "0.7891334730957372\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}