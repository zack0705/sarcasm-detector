{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarcasm_basic_1_lemm_pos.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3HhM4VVzp6Q",
        "outputId": "99caf2b8-3bef-417e-816b-273132a264cd"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger') \r\n",
        "from nltk.corpus import wordnet\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW4DI5Dqs64f"
      },
      "source": [
        "import pandas as pd, numpy as np, re, time\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwU740Vqux-p"
      },
      "source": [
        "# Loading data from json file\r\n",
        "data = pd.read_json('Sarcasm_Headlines_Dataset_v2.json', lines = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emyRdte1u0sf",
        "outputId": "6895c629-417b-4d3b-a9d0-9eb4609a9877"
      },
      "source": [
        "print(data.isnull().any(axis = 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_sarcastic    False\n",
            "headline        False\n",
            "article_link    False\n",
            "dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "jg4z_UmGvR3C",
        "outputId": "73364557-0c2a-4ce5-c385-57aae11482a3"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                       article_link\n",
              "0             1  ...  https://www.theonion.com/thirtysomething-scien...\n",
              "1             0  ...  https://www.huffingtonpost.com/entry/donna-edw...\n",
              "2             0  ...  https://www.huffingtonpost.com/entry/eat-your-...\n",
              "3             1  ...  https://local.theonion.com/inclement-weather-p...\n",
              "4             1  ...  https://www.theonion.com/mother-comes-pretty-c...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uctqlUQRu3bP"
      },
      "source": [
        "# Relacing special symbols and digits in headline column\r\n",
        "# re stands for Regular Expression\r\n",
        "data['headline'] = data['headline'].apply(lambda s : re.sub('[^a-zA-Z]', ' ', s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "bC0ggmtGwish",
        "outputId": "e15b146b-112a-4ad7-d995-e4284965b687"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep  totally nails why congress is falling...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies    deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word  strea...</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                       article_link\n",
              "0             1  ...  https://www.theonion.com/thirtysomething-scien...\n",
              "1             0  ...  https://www.huffingtonpost.com/entry/donna-edw...\n",
              "2             0  ...  https://www.huffingtonpost.com/entry/eat-your-...\n",
              "3             1  ...  https://local.theonion.com/inclement-weather-p...\n",
              "4             1  ...  https://www.theonion.com/mother-comes-pretty-c...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRAjZ64vu31w"
      },
      "source": [
        "# getting features and labels\r\n",
        "features = data['headline']\r\n",
        "labels = data['is_sarcastic']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRmDulTNxT84",
        "outputId": "959f398d-670d-4adf-95c8-87f6c18f4c8f"
      },
      "source": [
        "print(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        thirtysomething scientists unveil doomsday clo...\n",
            "1        dem rep  totally nails why congress is falling...\n",
            "2        eat your veggies    deliciously different recipes\n",
            "3        inclement weather prevents liar from getting t...\n",
            "4        mother comes pretty close to using word  strea...\n",
            "                               ...                        \n",
            "28614         jews to celebrate rosh hashasha or something\n",
            "28615    internal affairs investigator disappointed con...\n",
            "28616    the most beautiful acceptance speech this week...\n",
            "28617    mars probe destroyed by orbiting spielberg gat...\n",
            "28618                   dad clarifies this not a food stop\n",
            "Name: headline, Length: 28619, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLhi8TZl2cn-"
      },
      "source": [
        "def lemm(l):\r\n",
        "  ans = []\r\n",
        "  for i in range(len(l)):\r\n",
        "    y = nltk.pos_tag(nltk.word_tokenize(l[i]))\r\n",
        "    ans.append(y)\r\n",
        "  return(ans)\r\n",
        "#print(l[0])    \r\n",
        "#print(lemm(l))\r\n",
        "\r\n",
        "def pos_tagger(nltk_tag): \r\n",
        "    if nltk_tag.startswith('J'): \r\n",
        "        return wordnet.ADJ \r\n",
        "    elif nltk_tag.startswith('V'): \r\n",
        "        return wordnet.VERB \r\n",
        "    elif nltk_tag.startswith('N'): \r\n",
        "        return wordnet.NOUN \r\n",
        "    elif nltk_tag.startswith('R'): \r\n",
        "        return wordnet.ADV \r\n",
        "    else:           \r\n",
        "        return None\r\n",
        "\r\n",
        "ans = []\r\n",
        "list(filter(lambda x: ans.append(nltk.pos_tag(nltk.word_tokenize(x))), list(features)))\r\n",
        "#print(ans)\r\n",
        "\r\n",
        "for i in range(len(ans)):\r\n",
        "  for j in range(len(ans[i])):\r\n",
        "    ans[i][j] = (ans[i][j][0],pos_tagger(ans[i][j][1]))\r\n",
        "\r\n",
        "#print(ans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCNR1ohKzLzP"
      },
      "source": [
        "lm = WordNetLemmatizer()\r\n",
        "featureslm = []\r\n",
        "#list(filter(lambda x: featureslm.append(nltk.pos_tag(nltk.word_tokenize(y, i) for y,i in x)), ans))\r\n",
        "\r\n",
        "def sent(l):\r\n",
        "  ans = \"\"\r\n",
        "  for i in l:\r\n",
        "    if(i[1]):\r\n",
        "      ans += lm.lemmatize(i[0], i[1])\r\n",
        "    else:\r\n",
        "      ans += lm.lemmatize(i[0])\r\n",
        "    ans += ' '\r\n",
        "  return(ans[:-1])\r\n",
        "\r\n",
        "for i in ans:\r\n",
        "  featureslm.append(sent(i))\r\n",
        "\r\n",
        "#featureslm = features.apply(lambda x : ' '.join([lm.lemmatize(word, tag) for word in x]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IshpyTJJu7mw"
      },
      "source": [
        "# vectorizing the data with maximum of 5000 features\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "tv = TfidfVectorizer(max_features = 5000)\r\n",
        "features = list(featureslm)\r\n",
        "features = tv.fit_transform(features).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVpx4GvYu9Zo"
      },
      "source": [
        "# getting training and testing data\r\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = .20, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oesqfpXHu_RX",
        "outputId": "7beff347-56a8-4ce3-cd2d-27a46bb78b1a"
      },
      "source": [
        "# model 1:-\r\n",
        "# Using linear support vector classifier\r\n",
        "lsvc = LinearSVC()\r\n",
        "# training the model\r\n",
        "lsvc.fit(features_train, labels_train)\r\n",
        "# getting the score of train and test data\r\n",
        "print(lsvc.score(features_train, labels_train)) # 90.93\r\n",
        "print(lsvc.score(features_test, labels_test))   # 83.75\r\n",
        "# model 2:-\r\n",
        "# Using Gaussuan Naive Bayes\r\n",
        "gnb = GaussianNB()\r\n",
        "gnb.fit(features_train, labels_train)\r\n",
        "print(gnb.score(features_train, labels_train))  # 78.86\r\n",
        "print(gnb.score(features_test, labels_test))    # 73.80\r\n",
        "# model 3:-\r\n",
        "# Logistic Regression\r\n",
        "lr = LogisticRegression()\r\n",
        "lr.fit(features_train, labels_train)\r\n",
        "print(lr.score(features_train, labels_train))   # 88.16\r\n",
        "print(lr.score(features_test, labels_test))     # 83.08\r\n",
        "# model 4:-\r\n",
        "# Random Forest Classifier\r\n",
        "rfc = RandomForestClassifier(n_estimators = 10, random_state = 0)\r\n",
        "rfc.fit(features_train, labels_train)\r\n",
        "print(rfc.score(features_train, labels_train))  # 98.82\r\n",
        "print(rfc.score(features_test, labels_test))    # 79.71\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.913212491810439\n",
            "0.8232005590496156\n",
            "0.8044551212055033\n",
            "0.7299091544374563\n",
            "0.8798427604280411\n",
            "0.8242487770789657\n",
            "0.9886001310329766\n",
            "0.7854647099930119\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}